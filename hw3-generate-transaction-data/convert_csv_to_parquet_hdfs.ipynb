{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33378b75-f0f4-46bb-af95-0096eaba8ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "app_name = \"convert-csv-to-parquet-hdfs\"\n",
    "hdfs_host = \"rc1a-dataproc-m-0phjwjdfohabk5n0.mdb.yandexcloud.net\"\n",
    "src_dir = \"/fraud-data-src\"\n",
    "dest_dir = \"/fraud-data-parquet\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(app_name)\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)  # to pretty print pyspark.DataFrame in jupyter\n",
    "\n",
    "schema = StructType([StructField(\"transaction_id\", LongType(), True),\n",
    "                     StructField(\"tx_datetime\", TimestampType(), True),\n",
    "                     StructField(\"customer_id\", LongType(), True),\n",
    "                     StructField(\"terminal_id\", LongType(), True),\n",
    "                     StructField(\"tx_amount\", DoubleType(), True),\n",
    "                     StructField(\"tx_time_seconds\", LongType(), True),\n",
    "                     StructField(\"tx_time_days\", LongType(), True),\n",
    "                     StructField(\"tx_fraud\", LongType(), True),\n",
    "                     StructField(\"tx_fraud_scenario\", LongType(), True)])\n",
    "\n",
    "\n",
    "def convert_csv_to_parquet(spark_session, src_filepath, dest_filepath):\n",
    "    logging.info(f\"Converting {src_filepath} to {src_filepath}\")\n",
    "    src_filepath_hdfs = f\"hdfs://{hdfs_host}{src_filepath}\"\n",
    "    logging.info(f\"{src_filepath_hdfs=}\")\n",
    "    dest_filepath_hdfs = f\"hdfs://{hdfs_host}{dest_filepath}\"\n",
    "    logging.info(f\"{dest_filepath_hdfs=}\")\n",
    "    logging.info(f\"Loading dataframe from {src_filepath_hdfs=}\")\n",
    "    df = spark_session.read.schema(schema).option(\"comment\", \"#\").option(\"header\", False).csv(src_filepath_hdfs)\n",
    "    logging.info(f\"Writing dataframe to {dest_filepath_hdfs=}\")\n",
    "    df.coalesce(1).write.mode('overwrite').parquet(dest_filepath_hdfs)\n",
    "    logging.info(f\"Success. Converted {src_filepath} to {src_filepath}\")\n",
    "\n",
    "\n",
    "def run_convert_csv_to_parquet():\n",
    "    cmd = f\"hadoop fs -ls {src_dir} | sed '1d;s/  */ /g' | cut -d\\  -f8\"\n",
    "    files = subprocess.check_output(cmd, shell=True).strip().decode(\"utf-8\").split('\\n')\n",
    "\n",
    "    for src_filepath in files:\n",
    "        dest_filepath = f\"{dest_dir}/{Path(src_filepath).stem}.parquet\"\n",
    "        convert_csv_to_parquet(spark, src_filepath, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc9c99f-6648-45b1-8ff5-7c7391919589",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"{dest_dir}/2020-03-19.parquet\"\n",
    "df = spark.read.schema(schema).parquet(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2231cb8-66b9-40b6-862d-c4920360123c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565254"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_from = datetime.datetime(2020, 3, 20, 0, 0, 0)\n",
    "dt_to = datetime.datetime(2020, 3, 20, 23, 59, 59)\n",
    "day_df = df.filter((df.tx_datetime >= dt_from) & (df.tx_datetime <= dt_to))\n",
    "count_day_df = day_df.count()\n",
    "count_day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d45aa7a-c424-402a-9659-e6d42069e82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT customer_id)</th></tr>\n",
       "<tr><td>751854</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------------+\n",
       "|count(DISTINCT customer_id)|\n",
       "+---------------------------+\n",
       "|                     751854|\n",
       "+---------------------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_customer_id = day_df.select(countDistinct(\"customer_id\"))\n",
    "count_customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b67366e-33da-47ec-a2cf-ffb7e6f0f8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT terminal_id)</th></tr>\n",
       "<tr><td>1003</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------------+\n",
       "|count(DISTINCT terminal_id)|\n",
       "+---------------------------+\n",
       "|                       1003|\n",
       "+---------------------------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_terminal_id = day_df.select(countDistinct(\"terminal_id\"))\n",
    "count_terminal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69fc9008-a020-45fb-bd34-f140e1b64ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.081858977939866"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_df.count() / count_customer_id.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c7f1ac-19d2-4a7e-950f-860cf9912461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dest_filepath = f\"{dest_dir}/2020-03-19.parquet\"\n",
    "dest_filepath = f\"{dest_dir}/*.parquet\"\n",
    "df = spark.read.schema(schema).parquet(dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20eee048-8a1b-4d78-8982-8250434dcc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 12, 3, 23, 59, 59)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tx_datetime = df.select(max(df.tx_datetime)).collect()[0][0]\n",
    "max_tx_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e738d03-3db8-4e87-9123-ef91e4e3e2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 9, 4, 23, 59, 59)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = 90\n",
    "start_date = max_tx_datetime - datetime.timedelta(days=days)\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ace6d4a-59ea-48e3-9fec-ab34be0bf625",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_days_df = df.filter(df.tx_datetime >= start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a69cb185-91a9-4048-b794-4676a92d1ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 9, 4, 23, 59, 59)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_days_min_tx_datetime = last_days_df.select(min(last_days_df.tx_datetime)).collect()[0][0]\n",
    "last_days_min_tx_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34bd286c-94b5-448e-87a6-664a9a7339d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT customer_id)</th></tr>\n",
       "<tr><td>996611</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------------+\n",
       "|count(DISTINCT customer_id)|\n",
       "+---------------------------+\n",
       "|                     996611|\n",
       "+---------------------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_customer_id = df.select(countDistinct(\"customer_id\"))\n",
    "count_customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d003384-20ba-4b81-a964-797a08c69ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(DISTINCT terminal_id)</th></tr>\n",
       "<tr><td>1007</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------------------+\n",
       "|count(DISTINCT terminal_id)|\n",
       "+---------------------------+\n",
       "|                       1007|\n",
       "+---------------------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_terminal_id = df.select(countDistinct(\"terminal_id\"))\n",
    "count_terminal_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c563ca-8642-4acb-a8b7-083a5e68f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
